\chapter{Numerical Sequences and Series}

\Exercise1 Prove that convergence of $\{s_n\}$ implies convergence of
$\{\abs{s_n}\}$. Is the converse true?
\begin{proof}
  Suppose $\{s_n\}$ converges to $s$ for some complex sequence
  $\{s_n\}$ and $s\in C$. Let $\varepsilon > 0$ be arbitrary. Then we
  may find $N$ such that $\abs{s_n - s} < \varepsilon$ for all
  $n\geq N$. Then, by Exercise~\ref{exercise-abs-abs-x-minus-abs-y} we
  have
  \begin{equation*}
    \abs{\abs{s_n} - \abs{s}} \leq \abs{s_n - s} < \varepsilon
    \quad\text{for each $n\geq N$.}
  \end{equation*}
  Hence $\{\abs{s_n}\}$ converges to $\abs{s}$.

  Note that the converse is {\em not} necessarily true. For example
  the real sequence $\{a_n\}$ given by $a_n = (-1)^n$ does not
  converge even though $\{\abs{a_n}\}$ converges to $1$.
\end{proof}

\Exercise2 Calculate $\displaystyle\lim_{n\to\infty}(\sqrt{n^2+n}-n)$.
\begin{solution}
  We have
  \begin{align*}
    \lim_{n\to\infty}(\sqrt{n^2+n}-n)
    &= \lim_{n\to\infty}\frac{(\sqrt{n^2+n}-n)(\sqrt{n^2+n}+n)}
      {\sqrt{n^2+n}+n} \\[3pt]
    &= \lim_{n\to\infty}\frac{n}{\sqrt{n^2+n}+n} \\[3pt]
    &= \lim_{n\to\infty}\frac1{\sqrt{1+\frac{1}n}+1} \\
    &= \frac12. \qedhere
  \end{align*}
\end{solution}

\Exercise3 If $s_1 = \sqrt2$, and
\begin{equation*}
  s_{n+1} = \sqrt{2 + \sqrt{s_n}}
  \qquad\text{($n=1,2,3,\dots$),}
\end{equation*}
prove that $\{s_n\}$ converges, and that $s_n<2$ for
$n = 1,2,3,\dots$.
\begin{proof}
  We will show by induction on $n$ that $\{s_n\}$ is a strictly
  increasing sequence that is bounded above by $2$. Certainly
  $\sqrt2 < \sqrt{2 + \sqrt2} < 2$, so the base case is
  satisfied. Suppose $s_n < s_{n+1} < 2$ for a positive integer
  $n$. Then
  \begin{equation*}
    s_{n+2} = \sqrt{2 + \sqrt{s_{n+1}}} > \sqrt{2 + \sqrt{s_n}} = s_{n+1}
  \end{equation*}
  and
  \begin{equation*}
    s_{n+2} = \sqrt{2 + \sqrt{s_{n+1}}}
    < \sqrt{2 + \sqrt{2}} < \sqrt{4} = 2.
  \end{equation*}
  Therefore $s_{n+1} < s_{n+2} < 2$ and it follows that $\{s_n\}$ is
  monotonic and bounded, and hence must converge.
\end{proof}

\Exercise4 Find the upper and lower limits of the sequence $\{s_n\}$
defined by
\begin{equation*}
  s_1 = 0;\quad s_{2m} = \frac{s_{2m-1}}2;
  \quad s_{2m+1} = \frac12 + s_{2m}.
\end{equation*}
\begin{solution}
  $\{s_n\}$ is the sequence
  \begin{equation*}
    0, \frac12, \frac14, \frac34, \frac38, \frac78,
    \frac7{16}, \frac{15}{16}, \dots.
  \end{equation*}
  The odd terms of $\{s_n\}$ form the sequence
  \begin{equation*}
    0, \frac14, \frac38, \frac7{16}, \dots, \frac{2^{n-1}-1}{2^n}, \dots
  \end{equation*}
  while the even terms form the sequence
  \begin{equation*}
    \frac12, \frac34, \frac78, \frac{15}{16}, \dots,
    \frac{2^n-1}{2^n}, \dots.
  \end{equation*}
  So
  \begin{align*}
    \liminf_{n\to\infty}s_n
    &= \lim_{n\to\infty}\frac{2^{n-1} - 1}{2^n} \\
    &= \lim_{n\to\infty}\left(\frac12 - \frac1{2^n}\right) \\
    &= \frac12,
  \end{align*}
  and
  \begin{align*}
    \limsup_{n\to\infty}s_n
    &= \lim_{n\to\infty}\frac{2^{n} - 1}{2^n} \\
    &= \lim_{n\to\infty}\left(1 - \frac1{2^n}\right) \\
    &= 1. \qedhere
  \end{align*}
\end{solution}

\Exercise5 For any two real sequences $\{a_n\}$, $\{b_n\}$, prove that
\begin{equation*}
  \limsup_{n\to\infty}(a_n + b_n)
  \leq \limsup_{n\to\infty}a_n + \limsup_{n\to\infty}b_n,
\end{equation*}
provided the sum on the right is not of the form $\infty - \infty$.
\begin{proof}
  For each positive integer $n$, put $c_n = a_n + b_n$. Let
  \begin{equation*}
    \alpha = \limsup_{n\to\infty}a_n,
    \quad
    \beta = \limsup_{n\to\infty}b_n,
    \quad\text{and}\quad
    \gamma = \limsup_{n\to\infty}c_n.
  \end{equation*}
  If $\alpha = \infty$ and $\beta\neq-\infty$ then the result is
  clear, and the case where $\alpha = -\infty$ and $\beta\neq\infty$
  is similar.

  So suppose $\alpha$ and $\beta$ are both finite. Let $\{c_{n_i}\}$
  be a subsequence of $\{c_n\}$ that converges to $\gamma$. Now let
  $\{a_{n_{i_j}}\}$ be a subsequence of $\{a_{n_i}\}$ such that
  \begin{equation*}
    \lim_{j\to\infty}a_{n_{i_j}} = \limsup_{i\to\infty}a_{n_i}.
  \end{equation*}
  Now since $\{c_{n_{i_j}}\}$ is a subsequence of $\{c_{n_i}\}$, it
  converges to the same limit $\gamma$. Then
  \begin{equation*}
    \lim_{j\to\infty}b_{n_{i_j}} = \lim_{j\to\infty}(c_{n_{i_j}} - a_{n_{i_j}})
    = \lim_{j\to\infty}c_{n_{i_j}} - \lim_{j\to\infty}a_{n_{i_j}}
    = \gamma - \limsup_{i\to\infty}a_{n_i}.
  \end{equation*}
  Rearranging, we get
  \begin{equation*}
    \gamma = \limsup_{i\to\infty}a_{n_i} + \lim_{j\to\infty}b_{n_{i_j}}.
  \end{equation*}
  But
  \begin{equation*}
    \limsup_{i\to\infty}a_{n_i} \leq \alpha
    \quad\text{and}\quad
    \lim_{j\to\infty}b_{n_{i_j}} \leq \beta,
  \end{equation*}
  so
  \begin{equation*}
    \gamma \leq \alpha + \beta
  \end{equation*}
  and the proof is complete.
\end{proof}

\Exercise6 Investigate the behavior (convergence or divergence) of
$\sum a_n$ if
\begin{enumerate}
\item $a_n = \sqrt{n+1} - \sqrt{n}$
  \begin{solution}
    Let $s_n$ denote the $n$th partial sum of $\sum a_n$. A simple
    induction argument will show that $s_n = \sqrt{n+1} -
    \sqrt1$. Since $s_n\to\infty$ as $n\to\infty$, the series
    $\sum a_n$ diverges.
  \end{solution}
\item $\displaystyle a_n = \frac{\sqrt{n+1} - \sqrt{n}}n$
  \begin{solution}
    We have
    \begin{equation*}
      a_n = \frac{(\sqrt{n+1} - \sqrt{n})(\sqrt{n+1} + \sqrt{n})}
            {n(\sqrt{n+1} + \sqrt{n})}
      = \frac1{n\sqrt{n+1} + n\sqrt{n}}.
    \end{equation*}
    so
    \begin{equation*}
      a_n \leq \frac1{2n^{3/2}} < \frac1{n^{3/2}}.
    \end{equation*}
    So by comparison (Theorem~3.25) with the convergent series
    $\sum1/n^{3/2}$, we see that $\sum a_n$ converges.
  \end{solution}
\item $a_n = (\sqrt[n]{n} - 1)^n$
  \begin{solution}
    By Theorem~3.20 (c),
    \begin{equation*}
      \lim_{n\to\infty}\sqrt[n]{a_n} = \lim_{n\to\infty}(\sqrt[n]{n} - 1)
      = 1 - 1 = 0.
    \end{equation*}
    Therefore, by the root test (Theorem~3.33), the series $\sum a_n$
    converges.
  \end{solution}
\item $\displaystyle a_n = \frac1{1+z^n}$ for complex values of $z$
  \begin{solution}
    First note that, by Exercise~\ref{exercise-abs-abs-x-minus-abs-y},
    we have
    \begin{equation*}
      \abs{z^n + 1} = \abs{z^n - (-1)}
      \geq \abs{\abs{z^n} - \abs{-1}}
      = \abs{\abs{z}^n - 1}.
    \end{equation*}
    Then
    \begin{equation}
      \label{eq:abs-1-over-1-plus-z-n-inequality}
      \Abs{\frac1{1 + z^n}} \leq \frac1{\abs{\abs{z}^n - 1}}.
    \end{equation}

    Now suppose $\abs{z} > 1$. Then there is an integer $N$ such that
    $\abs{z}^n > 2$ for all $n\geq N$. That is,
    \begin{equation*}
      \frac1{\abs{z}^n - 1}\leq \frac2{\abs{z}^n}
      \quad\text{for $n\geq N$}.
    \end{equation*}
    Using this fact, \eqref{eq:abs-1-over-1-plus-z-n-inequality}
    becomes
    \begin{equation*}
      \Abs{\frac1{1 + z^n}} \leq \frac2{\abs{z}^n}
      \quad
      \text{for $n\geq N$}.
    \end{equation*}
    So by the comparison test with the convergent geometric series
    $\sum 2/\abs{z}^n$ we have that $\sum a_n$ also converges.

    In the case where $\abs{z} \leq 1$, it is easy to see that
    $a_n\not\to 0$ as $n\to\infty$, so $\sum a_n$ diverges.
  \end{solution}
\end{enumerate}

\Exercise7 Prove that the convergence of $\sum a_n$ implies the
convergence of
\begin{equation*}
  \sum\frac{\sqrt{a_n}}n,
\end{equation*}
if $a_n\geq0$.
\begin{proof}
  Since
  \begin{equation*}
    \left(\sqrt{a_n} + \frac1n\right)^2 \geq 0,
  \end{equation*}
  we may expand and rearrange to get
  \begin{equation}
    \label{eq:sqrt-a-n-inequality}
    \frac{\sqrt{a_n}}n \leq \frac12\left(a_n + \frac1{n^2}\right).
  \end{equation}
  Since $\sum a_n$ and $\sum1/n^2$ both converge, we know by
  Theorem~3.47 that their sum,
  \begin{equation*}
    \sum_{n=1}^\infty\left(a_n + \frac1{n^2}\right),
  \end{equation*}
  also converges. By the comparison test,
  \eqref{eq:sqrt-a-n-inequality} implies that $\sum\sqrt{a_n}/n$ must
  converge.
\end{proof}

\Exercise8 If $\sum a_n$ converges, and if $\{b_n\}$ is monotonic and
bounded, prove that $\sum a_nb_n$ converges.
\begin{proof}
  Let $A_n$ denote the $n$th partial sum of $\sum a_n$. That is,
  \begin{equation*}
    A_n = \sum_{k=1}^n a_k.
  \end{equation*}
  Suppose $\{A_n\}$ converges to $A$. We know that $\{b_n\}$ must
  converge, so set $b = \lim_{n\to\infty}b_n$. Then
  \begin{equation*}
    \lim_{n\to\infty}A_nb_n = Ab.
  \end{equation*}

  Now, since $\{A_n\}$ converges, it must be bounded, so we can find
  $M_0$ such that $\abs{A_n} < M_0$ for all $n$. We can also find
  $M_1$ such that $\abs{b_n} < M_1$ for all $n$. Take
  $M = \max(M_0, M_1)$. Then for any $\varepsilon>0$, we may find $N$
  such that
  \begin{equation*}
    \abs{A_nb_n - Ab} < \frac\varepsilon3
    \quad\text{and}\quad
    \abs{b_m - b_n} < \frac{\varepsilon}{3M}
    \quad\text{for all $m,n\geq N$}.
  \end{equation*}

  Since $\{b_n\}$ is monotonic, we have for all $q > p > N$ that
  \begin{align*}
    \Abs{\sum_{n=p}^{q-1} A_n(b_n - b_{n+1})}
    &\leq M\Abs{\sum_{n=p}^{q-1}(b_n - b_{n+1})} \\
    &= M\abs{b_p - b_q} < \frac{\varepsilon}3,
  \end{align*}
  and
  \begin{align*}
    \abs{A_qb_q - A_{p-1}b_p}
    &= \abs{A_qb_q - Ab + Ab - A_{p-1}b_p} \\
    &\leq \abs{A_qb_q - Ab} + \abs{A_{p-1}b_p - Ab} \\
    &< \frac\varepsilon3 + \frac\varepsilon3
    = \frac{2\varepsilon}3.
  \end{align*}

  Finally, using the partial summation formula from Theorem~3.41, we
  have
  \begin{align*}
    \Abs{\sum_{n=p}^q a_nb_n}
    &= \Abs{\sum_{n=p}^{q-1}A_n(b_n - b_{n+1}) + A_qb_q - A_{p-1}b_p} \\
    &\leq \Abs{\sum_{n=p}^{q-1}A_n(b_n - b_{n+1})} + \abs{A_qb_q - A_{p-1}b_p} \\
    &< \frac\varepsilon3 + \frac{2\varepsilon}3 \\
    &= \varepsilon.
  \end{align*}
  By the Cauchy criterion, $\sum a_nb_n$ converges.
\end{proof}

\Exercise9 Find the radius of convergence of each of the following
power series:
\begin{enumerate}
\item $\displaystyle\sum n^3z^n$
  \begin{solution}
    Using the ratio test, we have
    \begin{equation*}
      \lim_{n\to\infty}\Abs{\frac{(n+1)^3z^{n+1}}{n^3z^n}}
      = \lim_{n\to\infty}\frac{n+1}n\abs{z} = \abs{z}.
    \end{equation*}
    So the series converges when $\abs{z} < 1$. Therefore the radius
    of convergence is $R = 1$.
  \end{solution}
\item $\displaystyle\sum\frac{2^n}{n!}z^n$
  \begin{solution}
    Applying the ratio test again, we get,
    \begin{equation*}
      \lim_{n\to\infty}\Abs{\frac{2^{n+1}z^{n+1}n!}{2^nz^n(n+1)!}}
        = \lim_{n\to\infty}\frac2{n+1}\abs{z} = 0,
      \end{equation*}
      so $R = \infty$.
  \end{solution}
\item $\displaystyle\sum\frac{2^n}{n^2}z^n$
  \begin{solution}
    We have
    \begin{equation*}
      \lim_{n\to\infty}\Abs{\frac{2^{n+1}z^{n+1}n^2}{2^nz^n(n+1)^2}}
      = \lim_{n\to\infty}2\left(\frac{n}{n+1}\right)^2\abs{z}
      = 2\abs{z}
    \end{equation*}
    so $R = 1/2$.
  \end{solution}
\item $\displaystyle\sum\frac{n^3}{3^n}z^n$
  \begin{solution}
    Again,
    \begin{equation*}
      \lim_{n\to\infty}\Abs{\frac{(n+1)^3z^{n+1}3^n}{n^3z^n3^{n+1}}}
      = \lim_{n\to\infty}\frac13\left(\frac{n+1}n\right)^3\abs{z}
      = \frac13\abs{z},
    \end{equation*}
    so $R = 3$.
  \end{solution}
\end{enumerate}

\Exercise{10} Suppose that the coefficients of the power series
$\sum a_nz^n$ are integers, infinitely many of which are distinct from
zero. Prove that the radius of convergence is at most $1$.
\begin{proof}
  For contradiction, suppose that $\abs{z} > 1$ while the sum
  \begin{equation*}
    \sum_{n=0}^\infty a_nz^n
  \end{equation*}
  converges. Then we know that $a_nz^n\to0$. In particular if
  $\varepsilon = 1$, we may find an integer $N$ such that
  \begin{equation*}
    \abs{a_nz^n} < 1
    \quad\text{for all $n\geq N$}.
  \end{equation*}
  But since $a_n$ is an integer and is nonzero for infinitely many
  $n$, we may also find $n_0\geq N$ such that $a_{n_0}\geq1$. Then
  \begin{equation*}
    \abs{a_{n_0}z^{n_0}} = \abs{a_{n_0}}\abs{z^{n_0}} \geq 1.
  \end{equation*}
  This is a contradiction, so $\abs{z}$ cannot be greater than
  $1$. Therefore the radius of convergence is at most $1$.
\end{proof}

\Exercise{11} Suppose $a_n > 0$, $s_n = a_1 + \cdots + a_n$, and
$\sum a_n$ diverges.
\begin{enumerate}
\item Prove that $\displaystyle\sum\frac{a_n}{1 + a_n}$ diverges.
  \begin{proof}
    Suppose the sum converges. Then $a_n/(1 + a_n)\to0$, which implies
    that $a_n\to0$. So we can find a positive integer $N$ such that
    $a_n < 1$ for all $n\geq N$. Then for $n\geq N$ we have
    \begin{equation*}
      \frac{a_n}{1 + a_n} \geq \frac{a_n}{1 + 1} = \frac12a_n.
    \end{equation*}
    Then the series $\sum a_n/2$ and hence $\sum a_n$ must converge by
    the comparison test, a contradiction. Therefore
    $\sum a_n/(1 + a_n)$ must diverge.
  \end{proof}
\item Prove that
  \begin{equation*}
    \frac{a_{N+1}}{s_{N+1}} + \cdots
    + \frac{a_{N+k}}{s_{N+k}} \geq 1 - \frac{s_N}{s_{N+k}}
  \end{equation*}
  and deduce that $\displaystyle\sum\frac{a_n}{s_n}$ diverges.
  \begin{proof}
    Since $a_n > 0$, the sequence $\{s_n\}$ is monotonically
    increasing. Then for any positive integers $N$ and $k$, we have
    \begin{align*}
      \frac{a_{N+1}}{s_{N+1}} + \cdots
      + \frac{a_{N+k}}{s_{N+k}}
      &\geq \frac{a_{N+1}+\cdots+a_{N+k}}{s_{N+k}} \\
      &= \frac{s_{N+k} - s_N}{s_{N+k}} = 1 - \frac{s_N}{s_{N+k}}.
    \end{align*}
    This establishes the desired inequality.

    Now, since $s_n$ is monotonic, it cannot be bounded (for
    otherwise $\sum a_n$ would converge). So for any fixed $N>0$, we may
    find a positive integer $k$ so that
    \begin{equation*}
      s_{N+k} > 2s_N.
    \end{equation*}
    Then
    \begin{equation*}
      \sum_{n=1}^k\frac{a_{N+n}}{s_{N+n}}
      \geq 1 - \frac{s_N}{s_{N+k}} \geq 1 - \frac12 = \frac12.
    \end{equation*}
    Therefore $\sum a_n/s_n$ diverges by the Cauchy criterion.
  \end{proof}
\item Prove that
  \begin{equation*}
    \frac{a_n}{s_n^2}\leq\frac1{s_{n-1}} - \frac1{s_n}
  \end{equation*}
  and deduce that $\displaystyle\sum\frac{a_n}{s_n^2}$ converges.
  \begin{proof}
    For any $n$,
    \begin{equation}
      \label{eq:recip-s-n-minus-1-recip-s-n-ineq}
      \frac1{s_{n-1}}-\frac1{s_n} = \frac{s_n - s_{n-1}}{s_{n-1}s_n}
      = \frac{a_n}{s_{n-1}s_n} \geq \frac{a_n}{s_n^2}.
    \end{equation}
    Now notice that
    \begin{equation*}
      \sum_{n=2}^k\left(\frac1{s_{n-1}} - \frac1{s_n}\right)
      = \frac1{s_1} - \frac1{s_k}.
    \end{equation*}
    Since the right-hand side of this equation tends to $1/s_1$ as
    $k\to\infty$, we see that the sum on the left converges. By the
    comparison test with \eqref{eq:recip-s-n-minus-1-recip-s-n-ineq},
    it follows that $\sum a_n/s_n^2$ converges.
  \end{proof}
\item What can be said about
  \begin{equation*}
    \sum\frac{a_n}{1 + na_n}
    \quad\text{and}\quad
    \sum\frac{a_n}{1 + n^2a_n}?
  \end{equation*}
  \begin{solution}
    The series on the right must converge by comparison with the
    convergent series $\sum1/n^2$.

    However, the series on the left may converge or diverge depending
    on the nature of $\{a_n\}$. For example, if $a_n = 1$ for all $n$,
    then
    \begin{equation*}
      \frac{a_n}{1 + na_n} = \frac1{1 + n},
    \end{equation*}
    which is just the divergent harmonic series without the first
    term.

    On the other hand, if we set $a_n = 1$ when $n$ is a perfect
    square and $a_n = 1/n^2$ otherwise, then $\{a_n\}$ does diverge
    but $\sum a_n/(1 + na_n)$ converges, as we will now show. Let $P$
    be the set of perfect squares. Then
    \begin{align*}
      \sum_{n=1}^{m^2}\frac{a_n}{1 + na_n}
      &= \sum_{\substack{1\leq n\leq m^2 \\ n\in P}}\frac{a_n}{1 + na_n}
      + \sum_{\substack{1\leq n\leq m^2 \\ n\not\in P}}\frac{a_n}{1 + na_n} \\
      &= \sum_{n=1}^m\frac1{1 + n^2}
        + \sum_{\substack{1\leq n\leq m^2 \\ n\not\in P}}\frac1{n^2 + n} \\
      &\leq \sum_{n=1}^m\frac1{1 + n^2} + \sum_{n=1}^{m^2}\frac1{n^2 + n}.
    \end{align*}
    If we let $m\to\infty$, then the right-hand side converges, and it
    follows that $\sum a_n/(1 + na_n)$ also converges.
  \end{solution}
\end{enumerate}

\Exercise{12} Suppose $a_n > 0$ and $\sum a_n$ converges. Put
\begin{equation*}
  r_n = \sum_{m=n}^\infty a_m.
\end{equation*}
\begin{enumerate}
\item Prove that
  \begin{equation*}
    \frac{a_m}{r_m} + \cdots + \frac{a_n}{r_n} > 1 - \frac{r_n}{r_m}
  \end{equation*}
  if $m < n$, and deduce that $\sum\frac{a_n}{r_n}$ diverges.
  \begin{proof}
    Note that the sequence $\{r_n\}$ is strictly decreasing and
    bounded below by $0$. So if $m < n$, we have
    \begin{equation*}
      \frac{a_m}{r_m} + \cdots + \frac{a_n}{r_n}
      > \frac{a_m + \cdots + a_n}{r_m}
      = \frac{r_m - r_{n+1}}{r_m} > 1 - \frac{r_n}{r_m}.
    \end{equation*}
    Fix an $m > 0$. Since $r_n\to0$ we can always find $n > m$ so that
    $r_n < r_m/2$. Then $1 - r_n/r_m > 1/2$. So no matter how large
    $N$ is, it is possible to find $n>m\geq N$ such that
    \begin{equation*}
      \sum_{k=m}^n\frac{a_k}{r_k} > \frac12,
    \end{equation*}
    and therefore the series diverges by the Cauchy criterion.
  \end{proof}
\item Prove that
  \begin{equation*}
    \frac{a_n}{\sqrt{r_n}} < 2(\sqrt{r_n} - \sqrt{r_{n+1}})
  \end{equation*}
  and deduce that $\sum\frac{a_n}{\sqrt{r_n}}$ converges.
  \begin{proof}
    For any index $n$, we have
    \begin{align*}
      \frac{a_n}{\sqrt{r_n}}
      &= \frac{r_n - r_{n+1}}{\sqrt{r_n}} \\
      &= \frac{(\sqrt{r_n} + \sqrt{r_{n+1}})
        (\sqrt{r_n} - \sqrt{r_{n+1}})}{\sqrt{r_n}} \\
      &= \left(1 + \frac{\sqrt{r_{n+1}}}{\sqrt{r_n}}\right)
        (\sqrt{r_n} - \sqrt{r_{n+1}}) \\
      &< 2(\sqrt{r_n} - \sqrt{r_{n+1}}).
    \end{align*}
    Now observe that, since $r_n\to0$, we have
    \begin{align*}
      \sum_{n=1}^\infty(\sqrt{r_n} - \sqrt{r_{n+1}})
      &= \lim_{m\to\infty}\sum_{n=1}^m(\sqrt{r_n} - \sqrt{r_{n+1}}) \\
      &= \lim_{m\to\infty}(\sqrt{r_1} - \sqrt{r_{m+1}}) \\
      &= \sqrt{r_1}.
    \end{align*}
    This series converges, so by the comparison test,
    $\sum a_n/\sqrt{r_n}$ also converges.
  \end{proof}
\end{enumerate}

\Exercise{13} Prove that the Cauchy product of two absolutely
convergent series converges absolutely.
\begin{proof}
  We will imitate the proof of Theorem~3.50. Suppose $\sum a_n$ and
  $\sum b_n$ both converge absolutely, define
  \begin{equation*}
    c_n = \sum_{k=0}^n a_kb_{n-k}
  \end{equation*}
  for each positive integer $n$, and set
  \begin{equation*}
    \sum_{n=0}^\infty\abs{a_n} = A
    \quad\text{and}\quad
    \sum_{n=0}^\infty\abs{b_n} = B.
  \end{equation*}
  Further, put
  \begin{equation*}
    A_n = \sum_{k=0}^n\abs{a_k},
    \quad
    B_n = \sum_{k=0}^n\abs{b_k},
    \quad
    C_n = \sum_{k=0}^n\abs{c_k},
    \quad\text{and}\quad
    \beta_n = B_n - B.
  \end{equation*}
  Then
  \begin{align*}
    C_n &= \abs{a_0b_0} + \abs{a_0b_1 + a_1b_0}
          + \cdots + \abs{a_0b_n + a_1b_{n-1} + \cdots + a_nb_0} \\
        &\leq \abs{a_0}\abs{b_0} + (\abs{a_0}\abs{b_1}
          + \abs{a_1}\abs{b_0}) + \cdots + (\abs{a_0}\abs{b_n}
          + \cdots + \abs{a_n}\abs{b_0}) \\
        &= \abs{a_0}B_n + \abs{a_1}B_{n-1} + \cdots + \abs{a_n}B_0 \\
        &= \abs{a_0}(B + \beta_n) + \abs{a_1}(B + \beta_{n-1})
          + \cdots + \abs{a_n}(B + \beta_0) \\
        &= A_nB + \abs{a_0}\beta_n + \abs{a_1}\beta_{n-1}
          + \cdots + \abs{a_n}\beta_0.
  \end{align*}
  Now set
  \begin{equation*}
    \gamma_n = \abs{a_0}\beta_n + \abs{a_1}\beta_{n-1}
    + \cdots + \abs{a_n}\beta_0.
  \end{equation*}
  Let $\varepsilon > 0$ be given and note that $\beta_n\to0$. So we
  can choose $N$ such that $\abs{\beta_n}\leq\varepsilon$ for
  $n\geq N$. Then
  \begin{align*}
    \abs{\gamma_n}
    &\leq \abs{\beta_0\abs{a_n} + \cdots + \beta_N\abs{a_{n-N}}}
      + \abs{\beta_{N+1}\abs{a_{n-N-1}} + \cdots + \beta_n\abs{a_0}} \\
    &\leq \abs{\beta_0\abs{a_n} + \cdots + \beta_N\abs{a_{n-N}}}
      + \varepsilon A.
  \end{align*}
  Keeping $N$ fixed and letting $n\to\infty$ gives
  \begin{equation*}
    \limsup_{n\to\infty}\,\abs{\gamma_n}\leq\varepsilon A,
  \end{equation*}
  since $\abs{a_k}\to0$ as $k\to\infty$. Since $\varepsilon$ was
  arbitrary, this shows that $\lim_{n\to\infty}\gamma_n = 0$.

  Returning to $C_n$, we have
  \begin{equation*}
    C_n \leq A_nB + \gamma_n.
  \end{equation*}
  Since $A_nB\to AB$ and $\gamma_n\to0$, we see that the sequence
  $\{C_n\}$ is bounded above. But $\{C_n\}$ is a sequence of partial
  sums for a series in which every term is nonnegative, so the
  sequence $\{C_n\}$ is also monotonically increasing. Therefore
  $\sum\abs{c_n}$ converges, so $\sum c_n$ converges absolutely.
\end{proof}
