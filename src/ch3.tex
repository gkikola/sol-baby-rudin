\chapter{Numerical Sequences and Series}

\Exercise1 Prove that convergence of $\{s_n\}$ implies convergence of
$\{\abs{s_n}\}$. Is the converse true?
\begin{proof}
  Suppose $\{s_n\}$ converges to $s$ for some complex sequence
  $\{s_n\}$ and $s\in C$. Let $\varepsilon > 0$ be arbitrary. Then we
  may find $N$ such that $\abs{s_n - s} < \varepsilon$ for all
  $n\geq N$. Then, by Exercise~\ref{exercise-abs-abs-x-minus-abs-y} we
  have
  \begin{equation*}
    \abs{\abs{s_n} - \abs{s}} \leq \abs{s_n - s} < \varepsilon
    \quad\text{for each $n\geq N$.}
  \end{equation*}
  Hence $\{\abs{s_n}\}$ converges to $\abs{s}$.

  Note that the converse is {\em not} necessarily true. For example
  the real sequence $\{a_n\}$ given by $a_n = (-1)^n$ does not
  converge even though $\{\abs{a_n}\}$ converges to $1$.
\end{proof}

\Exercise2 Calculate $\displaystyle\lim_{n\to\infty}(\sqrt{n^2+n}-n)$.
\begin{solution}
  We have
  \begin{align*}
    \lim_{n\to\infty}(\sqrt{n^2+n}-n)
    &= \lim_{n\to\infty}\frac{(\sqrt{n^2+n}-n)(\sqrt{n^2+n}+n)}
      {\sqrt{n^2+n}+n} \\[3pt]
    &= \lim_{n\to\infty}\frac{n}{\sqrt{n^2+n}+n} \\[3pt]
    &= \lim_{n\to\infty}\frac1{\sqrt{1+\frac{1}n}+1} \\
    &= \frac12. \qedhere
  \end{align*}
\end{solution}

\Exercise3 If $s_1 = \sqrt2$, and
\begin{equation*}
  s_{n+1} = \sqrt{2 + \sqrt{s_n}}
  \qquad\text{($n=1,2,3,\dots$),}
\end{equation*}
prove that $\{s_n\}$ converges, and that $s_n<2$ for
$n = 1,2,3,\dots$.
\begin{proof}
  We will show by induction on $n$ that $\{s_n\}$ is a strictly
  increasing sequence that is bounded above by $2$. Certainly
  $\sqrt2 < \sqrt{2 + \sqrt2} < 2$, so the base case is
  satisfied. Suppose $s_n < s_{n+1} < 2$ for a positive integer
  $n$. Then
  \begin{equation*}
    s_{n+2} = \sqrt{2 + \sqrt{s_{n+1}}} > \sqrt{2 + \sqrt{s_n}} = s_{n+1}
  \end{equation*}
  and
  \begin{equation*}
    s_{n+2} = \sqrt{2 + \sqrt{s_{n+1}}}
    < \sqrt{2 + \sqrt{2}} < \sqrt{4} = 2.
  \end{equation*}
  Therefore $s_{n+1} < s_{n+2} < 2$ and it follows that $\{s_n\}$ is
  monotonic and bounded, and hence must converge.
\end{proof}

\Exercise4 Find the upper and lower limits of the sequence $\{s_n\}$
defined by
\begin{equation*}
  s_1 = 0;\quad s_{2m} = \frac{s_{2m-1}}2;
  \quad s_{2m+1} = \frac12 + s_{2m}.
\end{equation*}
\begin{solution}
  $\{s_n\}$ is the sequence
  \begin{equation*}
    0, \frac12, \frac14, \frac34, \frac38, \frac78,
    \frac7{16}, \frac{15}{16}, \dots.
  \end{equation*}
  The odd terms of $\{s_n\}$ form the sequence
  \begin{equation*}
    0, \frac14, \frac38, \frac7{16}, \dots, \frac{2^{n-1}-1}{2^n}, \dots
  \end{equation*}
  while the even terms form the sequence
  \begin{equation*}
    \frac12, \frac34, \frac78, \frac{15}{16}, \dots,
    \frac{2^n-1}{2^n}, \dots.
  \end{equation*}
  So
  \begin{align*}
    \liminf_{n\to\infty}s_n
    &= \lim_{n\to\infty}\frac{2^{n-1} - 1}{2^n} \\
    &= \lim_{n\to\infty}\left(\frac12 - \frac1{2^n}\right) \\
    &= \frac12,
  \end{align*}
  and
  \begin{align*}
    \limsup_{n\to\infty}s_n
    &= \lim_{n\to\infty}\frac{2^{n} - 1}{2^n} \\
    &= \lim_{n\to\infty}\left(1 - \frac1{2^n}\right) \\
    &= 1. \qedhere
  \end{align*}
\end{solution}

\Exercise5 For any two real sequences $\{a_n\}$, $\{b_n\}$, prove that
\begin{equation*}
  \limsup_{n\to\infty}(a_n + b_n)
  \leq \limsup_{n\to\infty}a_n + \limsup_{n\to\infty}b_n,
\end{equation*}
provided the sum on the right is not of the form $\infty - \infty$.
\begin{proof}
  For each positive integer $n$, put $c_n = a_n + b_n$. Let
  \begin{equation*}
    \alpha = \limsup_{n\to\infty}a_n,
    \quad
    \beta = \limsup_{n\to\infty}b_n,
    \quad\text{and}\quad
    \gamma = \limsup_{n\to\infty}c_n.
  \end{equation*}
  If $\alpha = \infty$ and $\beta\neq-\infty$ then the result is
  clear, and the case where $\alpha = -\infty$ and $\beta\neq\infty$
  is similar.

  So suppose $\alpha$ and $\beta$ are both finite. Let $\{c_{n_i}\}$
  be a subsequence of $\{c_n\}$ that converges to $\gamma$. Now let
  $\{a_{n_{i_j}}\}$ be a subsequence of $\{a_{n_i}\}$ such that
  \begin{equation*}
    \lim_{j\to\infty}a_{n_{i_j}} = \limsup_{i\to\infty}a_{n_i}.
  \end{equation*}
  Now since $\{c_{n_{i_j}}\}$ is a subsequence of $\{c_{n_i}\}$, it
  converges to the same limit $\gamma$. Then
  \begin{equation*}
    \lim_{j\to\infty}b_{n_{i_j}} = \lim_{j\to\infty}(c_{n_{i_j}} - a_{n_{i_j}})
    = \lim_{j\to\infty}c_{n_{i_j}} - \lim_{j\to\infty}a_{n_{i_j}}
    = \gamma - \limsup_{i\to\infty}a_{n_i}.
  \end{equation*}
  Rearranging, we get
  \begin{equation*}
    \gamma = \limsup_{i\to\infty}a_{n_i} + \lim_{j\to\infty}b_{n_{i_j}}.
  \end{equation*}
  But
  \begin{equation*}
    \limsup_{i\to\infty}a_{n_i} \leq \alpha
    \quad\text{and}\quad
    \lim_{j\to\infty}b_{n_{i_j}} \leq \beta,
  \end{equation*}
  so
  \begin{equation*}
    \gamma \leq \alpha + \beta
  \end{equation*}
  and the proof is complete.
\end{proof}

\Exercise6 Investigate the behavior (convergence or divergence) of
$\sum a_n$ if
\begin{enumerate}
\item $a_n = \sqrt{n+1} - \sqrt{n}$
  \begin{solution}
    Let $s_n$ denote the $n$th partial sum of $\sum a_n$. A simple
    induction argument will show that $s_n = \sqrt{n+1} -
    \sqrt1$. Since $s_n\to\infty$ as $n\to\infty$, the series
    $\sum a_n$ diverges.
  \end{solution}
\item $\displaystyle a_n = \frac{\sqrt{n+1} - \sqrt{n}}n$
  \begin{solution}
    We have
    \begin{equation*}
      a_n = \frac{(\sqrt{n+1} - \sqrt{n})(\sqrt{n+1} + \sqrt{n})}
            {n(\sqrt{n+1} + \sqrt{n})}
      = \frac1{n\sqrt{n+1} + n\sqrt{n}}.
    \end{equation*}
    so
    \begin{equation*}
      a_n \leq \frac1{2n^{3/2}} < \frac1{n^{3/2}}.
    \end{equation*}
    So by comparison (Theorem~3.25) with the convergent series
    $\sum1/n^{3/2}$, we see that $\sum a_n$ converges.
  \end{solution}
\item $a_n = (\sqrt[n]{n} - 1)^n$
  \begin{solution}
    By Theorem~3.20 (c),
    \begin{equation*}
      \lim_{n\to\infty}\sqrt[n]{a_n} = \lim_{n\to\infty}(\sqrt[n]{n} - 1)
      = 1 - 1 = 0.
    \end{equation*}
    Therefore, by the root test (Theorem~3.33), the series $\sum a_n$
    converges.
  \end{solution}
\item $\displaystyle a_n = \frac1{1+z^n}$ for complex values of $z$
  \begin{solution}
    First note that, by Exercise~\ref{exercise-abs-abs-x-minus-abs-y},
    we have
    \begin{equation*}
      \abs{z^n + 1} = \abs{z^n - (-1)}
      \geq \abs{\abs{z^n} - \abs{-1}}
      = \abs{\abs{z}^n - 1}.
    \end{equation*}
    Then
    \begin{equation}
      \label{eq:abs-1-over-1-plus-z-n-inequality}
      \Abs{\frac1{1 + z^n}} \leq \frac1{\abs{\abs{z}^n - 1}}.
    \end{equation}

    Now suppose $\abs{z} > 1$. Then there is an integer $N$ such that
    $\abs{z}^n > 2$ for all $n\geq N$. That is,
    \begin{equation*}
      \frac1{\abs{z}^n - 1}\leq \frac2{\abs{z}^n}
      \quad\text{for $n\geq N$}.
    \end{equation*}
    Using this fact, \eqref{eq:abs-1-over-1-plus-z-n-inequality}
    becomes
    \begin{equation*}
      \Abs{\frac1{1 + z^n}} \leq \frac2{\abs{z}^n}
      \quad
      \text{for $n\geq N$}.
    \end{equation*}
    So by the comparison test with the convergent geometric series
    $\sum 2/\abs{z}^n$ we have that $\sum a_n$ also converges.

    In the case where $\abs{z} \leq 1$, it is easy to see that
    $a_n\not\to 0$ as $n\to\infty$, so $\sum a_n$ diverges.
  \end{solution}
\end{enumerate}

\Exercise7 Prove that the convergence of $\sum a_n$ implies the
convergence of
\begin{equation*}
  \sum\frac{\sqrt{a_n}}n,
\end{equation*}
if $a_n\geq0$.
\begin{proof}
  Since
  \begin{equation*}
    \left(\sqrt{a_n} + \frac1n\right)^2 \geq 0,
  \end{equation*}
  we may expand and rearrange to get
  \begin{equation}
    \label{eq:sqrt-a-n-inequality}
    \frac{\sqrt{a_n}}n \leq \frac12\left(a_n + \frac1{n^2}\right).
  \end{equation}
  Since $\sum a_n$ and $\sum1/n^2$ both converge, we know by
  Theorem~3.47 that their sum,
  \begin{equation*}
    \sum_{n=1}^\infty\left(a_n + \frac1{n^2}\right),
  \end{equation*}
  also converges. By the comparison test,
  \eqref{eq:sqrt-a-n-inequality} implies that $\sum\sqrt{a_n}/n$ must
  converge.
\end{proof}

\Exercise8 If $\sum a_n$ converges, and if $\{b_n\}$ is monotonic and
bounded, prove that $\sum a_nb_n$ converges.
\begin{proof}
  Let $A_n$ denote the $n$th partial sum of $\sum a_n$. That is,
  \begin{equation*}
    A_n = \sum_{k=1}^n a_k.
  \end{equation*}
  Suppose $\{A_n\}$ converges to $A$. We know that $\{b_n\}$ must
  converge, so set $b = \lim_{n\to\infty}b_n$. Then
  \begin{equation*}
    \lim_{n\to\infty}A_nb_n = Ab.
  \end{equation*}

  Now, since $\{A_n\}$ converges, it must be bounded, so we can find
  $M_0$ such that $\abs{A_n} < M_0$ for all $n$. We can also find
  $M_1$ such that $\abs{b_n} < M_1$ for all $n$. Take
  $M = \max(M_0, M_1)$. Then for any $\varepsilon>0$, we may find $N$
  such that
  \begin{equation*}
    \abs{A_nb_n - Ab} < \frac\varepsilon3
    \quad\text{and}\quad
    \abs{b_m - b_n} < \frac{\varepsilon}{3M}
    \quad\text{for all $m,n\geq N$}.
  \end{equation*}

  Since $\{b_n\}$ is monotonic, we have for all $q > p > N$ that
  \begin{align*}
    \Abs{\sum_{n=p}^{q-1} A_n(b_n - b_{n+1})}
    &\leq M\Abs{\sum_{n=p}^{q-1}(b_n - b_{n+1})} \\
    &= M\abs{b_p - b_q} < \frac{\varepsilon}3,
  \end{align*}
  and
  \begin{align*}
    \abs{A_qb_q - A_{p-1}b_p}
    &= \abs{A_qb_q - Ab + Ab - A_{p-1}b_p} \\
    &\leq \abs{A_qb_q - Ab} + \abs{A_{p-1}b_p - Ab} \\
    &< \frac\varepsilon3 + \frac\varepsilon3
    = \frac{2\varepsilon}3.
  \end{align*}

  Finally, using the partial summation formula from Theorem~3.41, we
  have
  \begin{align*}
    \Abs{\sum_{n=p}^q a_nb_n}
    &= \Abs{\sum_{n=p}^{q-1}A_n(b_n - b_{n+1}) + A_qb_q - A_{p-1}b_p} \\
    &\leq \Abs{\sum_{n=p}^{q-1}A_n(b_n - b_{n+1})} + \abs{A_qb_q - A_{p-1}b_p} \\
    &< \frac\varepsilon3 + \frac{2\varepsilon}3 \\
    &= \varepsilon.
  \end{align*}
  By the Cauchy criterion, $\sum a_nb_n$ converges.
\end{proof}

\Exercise9 Find the radius of convergence of each of the following
power series:
\begin{enumerate}
\item $\displaystyle\sum n^3z^n$
  \begin{solution}
    Using the ratio test, we have
    \begin{equation*}
      \lim_{n\to\infty}\Abs{\frac{(n+1)^3z^{n+1}}{n^3z^n}}
      = \lim_{n\to\infty}\frac{n+1}n\abs{z} = \abs{z}.
    \end{equation*}
    So the series converges when $\abs{z} < 1$. Therefore the radius
    of convergence is $R = 1$.
  \end{solution}
\item $\displaystyle\sum\frac{2^n}{n!}z^n$
  \begin{solution}
    Applying the ratio test again, we get,
    \begin{equation*}
      \lim_{n\to\infty}\Abs{\frac{2^{n+1}z^{n+1}n!}{2^nz^n(n+1)!}}
        = \lim_{n\to\infty}\frac2{n+1}\abs{z} = 0,
      \end{equation*}
      so $R = \infty$.
  \end{solution}
\item $\displaystyle\sum\frac{2^n}{n^2}z^n$
  \begin{solution}
    We have
    \begin{equation*}
      \lim_{n\to\infty}\Abs{\frac{2^{n+1}z^{n+1}n^2}{2^nz^n(n+1)^2}}
      = \lim_{n\to\infty}2\left(\frac{n}{n+1}\right)^2\abs{z}
      = 2\abs{z}
    \end{equation*}
    so $R = 1/2$.
  \end{solution}
\item $\displaystyle\sum\frac{n^3}{3^n}z^n$
  \begin{solution}
    Again,
    \begin{equation*}
      \lim_{n\to\infty}\Abs{\frac{(n+1)^3z^{n+1}3^n}{n^3z^n3^{n+1}}}
      = \lim_{n\to\infty}\frac13\left(\frac{n+1}n\right)^3\abs{z}
      = \frac13\abs{z},
    \end{equation*}
    so $R = 3$.
  \end{solution}
\end{enumerate}

\Exercise{10} Suppose that the coefficients of the power series
$\sum a_nz^n$ are integers, infinitely many of which are distinct from
zero. Prove that the radius of convergence is at most $1$.
\begin{proof}
  For contradiction, suppose that $\abs{z} > 1$ while the sum
  \begin{equation*}
    \sum_{n=0}^\infty a_nz^n
  \end{equation*}
  converges. Then we know that $a_nz^n\to0$. In particular if
  $\varepsilon = 1$, we may find an integer $N$ such that
  \begin{equation*}
    \abs{a_nz^n} < 1
    \quad\text{for all $n\geq N$}.
  \end{equation*}
  But since $a_n$ is an integer and is nonzero for infinitely many
  $n$, we may also find $n_0\geq N$ such that $a_{n_0}\geq1$. Then
  \begin{equation*}
    \abs{a_{n_0}z^{n_0}} = \abs{a_{n_0}}\abs{z^{n_0}} \geq 1.
  \end{equation*}
  This is a contradiction, so $\abs{z}$ cannot be greater than
  $1$. Therefore the radius of convergence is at most $1$.
\end{proof}

\Exercise{11} Suppose $a_n > 0$, $s_n = a_1 + \cdots + a_n$, and
$\sum a_n$ diverges.
\begin{enumerate}
\item Prove that $\displaystyle\sum\frac{a_n}{1 + a_n}$ diverges.
  \begin{proof}
    Suppose the sum converges. Then $a_n/(1 + a_n)\to0$, which implies
    that $a_n\to0$. So we can find a positive integer $N$ such that
    $a_n < 1$ for all $n\geq N$. Then for $n\geq N$ we have
    \begin{equation*}
      \frac{a_n}{1 + a_n} \geq \frac{a_n}{1 + 1} = \frac12a_n.
    \end{equation*}
    Then the series $\sum a_n/2$ and hence $\sum a_n$ must converge by
    the comparison test, a contradiction. Therefore
    $\sum a_n/(1 + a_n)$ must diverge.
  \end{proof}
\item Prove that
  \begin{equation*}
    \frac{a_{N+1}}{s_{N+1}} + \cdots
    + \frac{a_{N+k}}{s_{N+k}} \geq 1 - \frac{s_N}{s_{N+k}}
  \end{equation*}
  and deduce that $\displaystyle\sum\frac{a_n}{s_n}$ diverges.
  \begin{proof}
    Since $a_n > 0$, the sequence $\{s_n\}$ is monotonically
    increasing. Then for any positive integers $N$ and $k$, we have
    \begin{align*}
      \frac{a_{N+1}}{s_{N+1}} + \cdots
      + \frac{a_{N+k}}{s_{N+k}}
      &\geq \frac{a_{N+1}+\cdots+a_{N+k}}{s_{N+k}} \\
      &= \frac{s_{N+k} - s_N}{s_{N+k}} = 1 - \frac{s_N}{s_{N+k}}.
    \end{align*}
    This establishes the desired inequality.

    Now, since $s_n$ is monotonic, it cannot be bounded (for
    otherwise $\sum a_n$ would converge). So for any fixed $N>0$, we may
    find a positive integer $k$ so that
    \begin{equation*}
      s_{N+k} > 2s_N.
    \end{equation*}
    Then
    \begin{equation*}
      \sum_{n=1}^k\frac{a_{N+n}}{s_{N+n}}
      \geq 1 - \frac{s_N}{s_{N+k}} \geq 1 - \frac12 = \frac12.
    \end{equation*}
    Therefore $\sum a_n/s_n$ diverges by the Cauchy criterion.
  \end{proof}
\item Prove that
  \begin{equation*}
    \frac{a_n}{s_n^2}\leq\frac1{s_{n-1}} - \frac1{s_n}
  \end{equation*}
  and deduce that $\displaystyle\sum\frac{a_n}{s_n^2}$ converges.
  \begin{proof}
    For any $n$,
    \begin{equation}
      \label{eq:recip-s-n-minus-1-recip-s-n-ineq}
      \frac1{s_{n-1}}-\frac1{s_n} = \frac{s_n - s_{n-1}}{s_{n-1}s_n}
      = \frac{a_n}{s_{n-1}s_n} \geq \frac{a_n}{s_n^2}.
    \end{equation}
    Now notice that
    \begin{equation*}
      \sum_{n=2}^k\left(\frac1{s_{n-1}} - \frac1{s_n}\right)
      = \frac1{s_1} - \frac1{s_k}.
    \end{equation*}
    Since the right-hand side of this equation tends to $1/s_1$ as
    $k\to\infty$, we see that the sum on the left converges. By the
    comparison test with \eqref{eq:recip-s-n-minus-1-recip-s-n-ineq},
    it follows that $\sum a_n/s_n^2$ converges.
  \end{proof}
\item What can be said about
  \begin{equation*}
    \sum\frac{a_n}{1 + na_n}
    \quad\text{and}\quad
    \sum\frac{a_n}{1 + n^2a_n}?
  \end{equation*}
  \begin{solution}
    The series on the right must converge by comparison with the
    convergent series $\sum1/n^2$.

    However, the series on the left may converge or diverge depending
    on the nature of $\{a_n\}$. For example, if $a_n = 1$ for all $n$,
    then
    \begin{equation*}
      \frac{a_n}{1 + na_n} = \frac1{1 + n},
    \end{equation*}
    which is just the divergent harmonic series without the first
    term.

    On the other hand, if we set $a_n = 1$ when $n$ is a perfect
    square and $a_n = 1/n^2$ otherwise, then $\{a_n\}$ does diverge
    but $\sum a_n/(1 + na_n)$ converges, as we will now show. Let $P$
    be the set of perfect squares. Then
    \begin{align*}
      \sum_{n=1}^{m^2}\frac{a_n}{1 + na_n}
      &= \sum_{\substack{1\leq n\leq m^2 \\ n\in P}}\frac{a_n}{1 + na_n}
      + \sum_{\substack{1\leq n\leq m^2 \\ n\not\in P}}\frac{a_n}{1 + na_n} \\
      &= \sum_{n=1}^m\frac1{1 + n^2}
        + \sum_{\substack{1\leq n\leq m^2 \\ n\not\in P}}\frac1{n^2 + n} \\
      &\leq \sum_{n=1}^m\frac1{1 + n^2} + \sum_{n=1}^{m^2}\frac1{n^2 + n}.
    \end{align*}
    If we let $m\to\infty$, then the right-hand side converges, and it
    follows that $\sum a_n/(1 + na_n)$ also converges.
  \end{solution}
\end{enumerate}

\Exercise{12} Suppose $a_n > 0$ and $\sum a_n$ converges. Put
\begin{equation*}
  r_n = \sum_{m=n}^\infty a_m.
\end{equation*}
\begin{enumerate}
\item Prove that
  \begin{equation*}
    \frac{a_m}{r_m} + \cdots + \frac{a_n}{r_n} > 1 - \frac{r_n}{r_m}
  \end{equation*}
  if $m < n$, and deduce that $\sum\frac{a_n}{r_n}$ diverges.
  \begin{proof}
    Note that the sequence $\{r_n\}$ is strictly decreasing and
    bounded below by $0$. So if $m < n$, we have
    \begin{equation*}
      \frac{a_m}{r_m} + \cdots + \frac{a_n}{r_n}
      > \frac{a_m + \cdots + a_n}{r_m}
      = \frac{r_m - r_{n+1}}{r_m} > 1 - \frac{r_n}{r_m}.
    \end{equation*}
    Fix an $m > 0$. Since $r_n\to0$ we can always find $n > m$ so that
    $r_n < r_m/2$. Then $1 - r_n/r_m > 1/2$. So no matter how large
    $N$ is, it is possible to find $n>m\geq N$ such that
    \begin{equation*}
      \sum_{k=m}^n\frac{a_k}{r_k} > \frac12,
    \end{equation*}
    and therefore the series diverges by the Cauchy criterion.
  \end{proof}
\item Prove that
  \begin{equation*}
    \frac{a_n}{\sqrt{r_n}} < 2(\sqrt{r_n} - \sqrt{r_{n+1}})
  \end{equation*}
  and deduce that $\sum\frac{a_n}{\sqrt{r_n}}$ converges.
  \begin{proof}
    For any index $n$, we have
    \begin{align*}
      \frac{a_n}{\sqrt{r_n}}
      &= \frac{r_n - r_{n+1}}{\sqrt{r_n}} \\
      &= \frac{(\sqrt{r_n} + \sqrt{r_{n+1}})
        (\sqrt{r_n} - \sqrt{r_{n+1}})}{\sqrt{r_n}} \\
      &= \left(1 + \frac{\sqrt{r_{n+1}}}{\sqrt{r_n}}\right)
        (\sqrt{r_n} - \sqrt{r_{n+1}}) \\
      &< 2(\sqrt{r_n} - \sqrt{r_{n+1}}).
    \end{align*}
    Now observe that, since $r_n\to0$, we have
    \begin{align*}
      \sum_{n=1}^\infty(\sqrt{r_n} - \sqrt{r_{n+1}})
      &= \lim_{m\to\infty}\sum_{n=1}^m(\sqrt{r_n} - \sqrt{r_{n+1}}) \\
      &= \lim_{m\to\infty}(\sqrt{r_1} - \sqrt{r_{m+1}}) \\
      &= \sqrt{r_1}.
    \end{align*}
    This series converges, so by the comparison test,
    $\sum a_n/\sqrt{r_n}$ also converges.
  \end{proof}
\end{enumerate}

\Exercise{13} Prove that the Cauchy product of two absolutely
convergent series converges absolutely.
\begin{proof}
  We will imitate the proof of Theorem~3.50. Suppose $\sum a_n$ and
  $\sum b_n$ both converge absolutely, define
  \begin{equation*}
    c_n = \sum_{k=0}^n a_kb_{n-k}
  \end{equation*}
  for each positive integer $n$, and set
  \begin{equation*}
    \sum_{n=0}^\infty\abs{a_n} = A
    \quad\text{and}\quad
    \sum_{n=0}^\infty\abs{b_n} = B.
  \end{equation*}
  Further, put
  \begin{equation*}
    A_n = \sum_{k=0}^n\abs{a_k},
    \quad
    B_n = \sum_{k=0}^n\abs{b_k},
    \quad
    C_n = \sum_{k=0}^n\abs{c_k},
    \quad\text{and}\quad
    \beta_n = B_n - B.
  \end{equation*}
  Then
  \begin{align*}
    C_n &= \abs{a_0b_0} + \abs{a_0b_1 + a_1b_0}
          + \cdots + \abs{a_0b_n + a_1b_{n-1} + \cdots + a_nb_0} \\
        &\leq \abs{a_0}\abs{b_0} + (\abs{a_0}\abs{b_1}
          + \abs{a_1}\abs{b_0}) + \cdots + (\abs{a_0}\abs{b_n}
          + \cdots + \abs{a_n}\abs{b_0}) \\
        &= \abs{a_0}B_n + \abs{a_1}B_{n-1} + \cdots + \abs{a_n}B_0 \\
        &= \abs{a_0}(B + \beta_n) + \abs{a_1}(B + \beta_{n-1})
          + \cdots + \abs{a_n}(B + \beta_0) \\
        &= A_nB + \abs{a_0}\beta_n + \abs{a_1}\beta_{n-1}
          + \cdots + \abs{a_n}\beta_0.
  \end{align*}
  Now set
  \begin{equation*}
    \gamma_n = \abs{a_0}\beta_n + \abs{a_1}\beta_{n-1}
    + \cdots + \abs{a_n}\beta_0.
  \end{equation*}
  Let $\varepsilon > 0$ be given and note that $\beta_n\to0$. So we
  can choose $N$ such that $\abs{\beta_n}\leq\varepsilon$ for
  $n\geq N$. Then
  \begin{align*}
    \abs{\gamma_n}
    &\leq \abs{\beta_0\abs{a_n} + \cdots + \beta_N\abs{a_{n-N}}}
      + \abs{\beta_{N+1}\abs{a_{n-N-1}} + \cdots + \beta_n\abs{a_0}} \\
    &\leq \abs{\beta_0\abs{a_n} + \cdots + \beta_N\abs{a_{n-N}}}
      + \varepsilon A.
  \end{align*}
  Keeping $N$ fixed and letting $n\to\infty$ gives
  \begin{equation*}
    \limsup_{n\to\infty}\,\abs{\gamma_n}\leq\varepsilon A,
  \end{equation*}
  since $\abs{a_k}\to0$ as $k\to\infty$. Since $\varepsilon$ was
  arbitrary, this shows that $\lim_{n\to\infty}\gamma_n = 0$.

  Returning to $C_n$, we have
  \begin{equation*}
    C_n \leq A_nB + \gamma_n.
  \end{equation*}
  Since $A_nB\to AB$ and $\gamma_n\to0$, we see that the sequence
  $\{C_n\}$ is bounded above. But $\{C_n\}$ is a sequence of partial
  sums for a series in which every term is nonnegative, so the
  sequence $\{C_n\}$ is also monotonically increasing. Therefore
  $\sum\abs{c_n}$ converges, so $\sum c_n$ converges absolutely.
\end{proof}

% \Exercise{14} If $\{s_n\}$ is a complex sequence, define its
% arithmetic means $\sigma_n$ by
% \begin{equation*}
%   \sigma_n = \frac{s_0 + s_1 + \cdots + s_n}{n + 1}
%   \quad
%   (n = 0, 1, 2, \dots).
% \end{equation*}
% \begin{enumerate}
% \item If $\lim s_n = s$, prove that $\lim\sigma_n = s$.
%   \begin{proof}
%     Let $\lim s_n = s$. For all nonnegative integers $n$ we have
%     \begin{align}
%       \begin{split}
%         \label{eq:sum-abs-s-0-minus-s}
%         \abs{\sigma_n - s}
%         &= \Abs{\frac{s_0 + s_1 + \cdots + s_n}{n+1} - s} \\
%         &= \frac1{n + 1}\abs{s_0 + s_1 + \cdots + s_n - (n + 1)s} \\
%         &= \frac1{n + 1}\abs{(s_0 - s) + (s_1 - s)
%           + \cdots + (s_n - s)} \\
%         &\leq \frac1{n + 1}\left(\abs{s_0 - s} + \abs{s_1 - s}
%           + \cdots + \abs{s_n - s}\right).
%       \end{split}
%     \end{align}
%     Since $\{s_n\}$ converges it must be bounded (Theorem~3.2~(c)), so
%     let $M > \abs{s_n}$ for all nonnegative integers $n$. Then
%     \begin{equation}
%       \label{eq:bound-for-sn-minus-s}
%       \abs{s_n - s} \leq \abs{s_n} + \abs{s} < M + \abs{s}
%       \quad\text{for all $n\geq0$}.
%     \end{equation}

%     Now let $\varepsilon > 0$ be arbitrary. We may find a positive
%     integer $N$ such that
%     \begin{equation}
%       \label{eq:abs-sn-minus-s}
%       \abs{s_n - s} < \frac\varepsilon2
%       \quad\text{for all $n\geq N$}.
%     \end{equation}
%     Set
%     \begin{equation}
%       \label{eq:define-N0}
%       N_0 = \frac{2(N + 1)(M + \abs{s})}\varepsilon.
%     \end{equation}
%     Using \eqref{eq:sum-abs-s-0-minus-s},
%     \eqref{eq:bound-for-sn-minus-s}, \eqref{eq:abs-sn-minus-s}, and
%     \eqref{eq:define-N0}, we have for all $n\geq N_0$ that
%     \begin{align*}
%       \abs{\sigma_n - s}
%       &\leq \frac1{n+1}\sum_{i=0}^N\abs{s_i-s}
%         + \frac1{n+1}\sum_{i=N+1}^n\abs{s_i-s} \\
%       &\leq \frac{\varepsilon(N+1)(M + \abs{s})}{2(N+1)(M + \abs{s})}
%         + \frac1{n+1}\left(\frac\varepsilon2\right)(n - N) \\
%       &\leq \frac\varepsilon2 + \frac\varepsilon2 = \varepsilon.
%     \end{align*}
%     Therefore $\lim_{n\to\infty}\sigma_n = s$.
%   \end{proof}
% \item Construct a sequence $\{s_n\}$ which does not converge, although
%   $\lim\sigma_n = 0$.
%   \begin{solution}
%     For each positive integer $n$, set $s_n = (-1)^n$. Obviously
%     $\{s_n\}$ does not converge, but
%     \begin{equation*}
%       \abs{\sigma_n} \leq \frac1{n+1}
%     \end{equation*}
%     so $\sigma_n\to0$.
%   \end{solution}
% \item Can it happen that $s_n > 0$ for all $n$ and that
%   $\limsup s_n = \infty$, although $\lim\sigma_n = 0$?
%   \begin{solution}
%     For each $n\geq0$, define
%     \begin{equation*}
%       s_n =
%       \begin{cases}
%         \sqrt{n} & \text{if $n = k^2$ for some $k\in Z$}, \\
%         1/n & \text{otherwise}.
%       \end{cases}
%     \end{equation*}
%     Then
%     \begin{equation*}
%       \sigma_{n^2} \leq \sum_{k=1}^{n^2}\frac1k + \sum_{k=1}^nk
%     \end{equation*}
%   \end{solution}
% \item Put $a_n = s_n - s_{n-1}$, for $n\geq1$. Show that
%   \begin{equation*}
%     s_n - \sigma_n = \frac1{n+1}\sum_{k=1}^nka_k.
%   \end{equation*}
%   Assume that $\lim(na_n) = 0$ and that $\{\sigma_n\}$
%   converges. Prove that $\{s_n\}$ converges.
% \item Derive the last conclusion from a weaker hypothesis: Assume
%   $M < \infty$, $\abs{na_n}\leq M$ for all $n$, and
%   $\lim\sigma_n = \sigma$. Prove that $\lim s_n = \sigma$, by
%   completing the following outline:

%   If $m < n$, then
%   \begin{equation*}
%     s_n - \sigma_n = \frac{m+1}{n-m}(\sigma_n - \sigma_m)
%     + \frac1{n-m}\sum_{i=m+1}^n(s_n - s_i).
%   \end{equation*}
%   For these $i$,
%   \begin{equation*}
%     \abs{s_n - s_i} \leq \frac{(n-i)M}{i+1} \leq \frac{(n-m-1)M}{m+2}.
%   \end{equation*}

%   Fix $\varepsilon > 0$ and associate with each $n$ the integer $m$
%   that satisfies
%   \begin{equation*}
%     m \leq \frac{n - \varepsilon}{1 + \varepsilon} < m + 1.
%   \end{equation*}
%   Then $(m+1)/(n-m)\leq1/\varepsilon$ and
%   $\abs{s_n-s_i} < M\varepsilon$. Hence
%   \begin{equation*}
%     \limsup_{n\to\infty}\abs{s_n - \sigma} \leq M\varepsilon.
%   \end{equation*}
%   Since $\varepsilon$ was arbitrary, $\lim s_n = \sigma$.
% \end{enumerate}

\Exercise{15} Definition~3.21 can be extended to the case in which the
$a_n$ lie in some fixed $R^k$. Absolute convergence is defined as
convergence of $\sum\abs{\vec{a}_n}$. Show that Theorems 3.22, 3.23,
3.25(a), 3.33, 3.34, 3.42, 3.45, 3.47, and 3.55 are true in this more
general setting.
\begin{thm}
  $\sum\vec{a}_n$ converges if and only if for every $\varepsilon > 0$
  there is an integer $N$ such that
  \begin{equation*}
    \Abs{\sum_{k=n}^m\vec{a}_k}\leq\varepsilon
  \end{equation*}
  if $m\geq n\geq N$.
\end{thm}
\begin{proof}
  Consider the sequence $\{\vec{a}_n\}$ in $R^t$ given by
  \begin{equation*}
    \vec{a}_n = (a_{1,n}, a_{2,n}, \dots, a_{t,n}).
  \end{equation*}

  Combining Theorem~3.4 with the original Theorem~3.22, we have that
  $\sum\vec{a}_n$ converges if and only if for each $\varepsilon_i>0$
  ($i = 1,2,\dots,t$) there is $N_i$ such that
  \begin{equation}
    \label{eq:partial-sum-of-vectors-is-cauchy}
    \Abs{\sum_{k=n}^ma_{i,k}} \leq \varepsilon_i
    \quad\text{for all $m\geq n\geq N_i$}.
  \end{equation}

  Suppose \eqref{eq:partial-sum-of-vectors-is-cauchy} holds and let
  $\varepsilon>0$. For each $i$, set
  $\varepsilon_i = \varepsilon/\sqrt{t}$ and find the corresponding
  $N_i$. Then if $J = \max(N_1,N_2,\dots,N_t)$ we have for all
  $m\geq n\geq J$ that
  \begin{equation*}
    \Abs{\sum_{k=n}^m\vec{a}_k}
    = \sqrt{\left(\sum_{k=n}^ma_{1,k}\right)^2
      + \cdots
      + \left(\sum_{k=n}^ma_{t,k}\right)^2}
    \leq \sqrt{\varepsilon^2} = \varepsilon.
  \end{equation*}

  Conversely, let each $\varepsilon_i>0$ be given and choose $N$ such that
  \begin{equation*}
    \Abs{\sum_{k=n}^m\vec{a}_k}\leq\min(\varepsilon_1,
    \dots,\varepsilon_t)
    \quad\text{for $m\geq n\geq N$}.
  \end{equation*}
  Then for each $i$ and for all $m\geq n\geq N$ we have
  \begin{equation*}
    \Abs{\sum_{k=n}^ma_{i,k}}
    = \sqrt{\left(\sum_{k=n}^ma_{i,k}\right)^2}
    \leq \sqrt{\left(\sum_{k=n}^ma_{1,k}\right)^2
      +\cdots+
      \left(\sum_{k=n}^ma_{t,k}\right)^2} \leq \varepsilon_i.
  \end{equation*}
  Therefore \eqref{eq:partial-sum-of-vectors-is-cauchy} holds for each
  $i$ and the proof is complete.
\end{proof}
\begin{thm}
  If $\sum\vec{a}_n$ converges, then $\lim_{n\to\infty}\vec{a}_n = \vec0$.
\end{thm}
\begin{proof}
  This is immediate from Theorem~3.4 combined with the original
  Theorem~3.23.
\end{proof}
\begin{thm}
  If $\abs{\vec{a}_n}\leq c_n$ for $n\geq N_0$, where $N_0$ is
  some fixed integer, and if $\sum c_n$ converges, then
  $\sum\vec{a}_n$ converges.
\end{thm}
\begin{proof}
  The proof is the same as the original proof of Theorem~3.25: given
  $\varepsilon>0$, by the Cauchy criterion there exists $N\geq N_0$
  such that $m\geq n\geq N$ implies
  \begin{equation*}
    \sum_{k=n}^m c_k\leq\varepsilon.
  \end{equation*}
  By the triangle inequality,
  \begin{equation*}
    \Abs{\sum_{k=n}^m\vec{a}_k}\leq\sum_{k=n}^m\abs{\vec{a}_k}
    \leq\sum_{k=n}^mc_k\leq\varepsilon. \qedhere
  \end{equation*}
\end{proof}
\begin{thm}[Root Test]
  Given $\sum\vec{a}_n$, put
  \begin{equation*}
    \alpha = \limsup_{n\to\infty}\sqrt[n]{\abs{\vec{a}_n}}.
  \end{equation*}
  Then
  \begin{enumerate}
  \item if $\alpha < 1$, $\sum\vec{a}_n$ converges;
  \item if $\alpha > 1$, $\sum\vec{a}_n$ diverges;
  \item if $\alpha = 1$, the test gives no information.
  \end{enumerate}
\end{thm}
\begin{proof}
  Again, this proof is an easy generalization of the original proof of
  Theorem~3.33:

  If $\alpha < 1$, choose $\beta$ so that
  $\alpha < \beta < 1$. Then we can find an integer $N$ such that
  \begin{equation*}
    \sqrt[n]{\abs{\vec{a}_n}} < \beta
    \quad\text{for $n\geq N$}.
  \end{equation*}
  Then $\abs{\vec{a}_n}<\beta^n$ for all $n\geq N$, and the
  convergence of $\sum\vec{a}_n$ follows from the comparison test,
  since $\sum\beta^n$ converges.

  If $\alpha > 1$ then there is a sequence $\{n_k\}$ such that
  $\sqrt[n]{\abs{\vec{a}_{n_k}}}\to\alpha$. Hence
  $\abs{\vec{a}_n} > 1$ for infinitely many values of $n$ and we
  cannot have $\vec{a}_n\to\vec0$. Therefore $\sum\vec{a}_n$ diverges.

  The fact that $\sum1/n$ diverges while $\sum1/n^2$ converges shows
  that $\alpha=1$ gives no information about convergence.
\end{proof}
\begin{thm}[Ratio Test]
  The series $\sum\vec{a}_n$
  \begin{enumerate}
  \item converges if
    \begin{equation*}
      \limsup_{n\to\infty}\frac{\abs{\vec{a}_{n+1}}}
      {\abs{\vec{a}_n}} < 1,
    \end{equation*}
  \item diverges if
    \begin{equation*}
      \frac{\abs{\vec{a}_{n+1}}}{\abs{\vec{a}_n}}\geq1
      \quad\text{for all $n\geq n_0$},
    \end{equation*}
    where $n_0$ is some fixed integer.
  \end{enumerate}
\end{thm}
\begin{proof}
  If the first condition holds, then we can find $\beta<1$ and an
  integer $N$ such that
  \begin{equation*}
    \frac{\abs{\vec{a}_{n+1}}}{\abs{\vec{a}_n}}<\beta
    \quad\text{for $n\geq N$}.
  \end{equation*}
  Then
  \begin{align*}
    \abs{\vec{a}_{N+1}} &< \beta\abs{\vec{a}_N}, \\
    \abs{\vec{a}_{N+2}} &< \beta\abs{\vec{a}_{N+1}} < \beta^2\abs{\vec{a}_N}, \\
                        &\;\;\vdots \\
    \abs{\vec{a}_{N+p}} &< \beta^p\abs{\vec{a}_N}.
  \end{align*}
  So for $n\geq N$,
  \begin{equation*}
    \abs{\vec{a}_n} < \abs{\vec{a}_N}\beta^{-N}\beta^n,
  \end{equation*}
  and convergence follows from the comparison test since $\sum\beta^n$
  converges.

  In the case where $\abs{\vec{a}_{n+1}}\geq\abs{\vec{a}_n}$ for
  $n\geq n_0$, it is clear that $\vec{a}_n$ does not tend to $\vec0$
  and $\sum\vec{a}_n$ diverges.
\end{proof}
\begin{thm}
  Suppose
  \begin{enumerate}
  \item the partial sums $\vec{A}_n$ of $\sum\vec{a}_n$ form a bounded
    sequence;
  \item $b_0\geq b_1\geq b_2\geq\cdots$;
  \item $\displaystyle\lim_{n\to\infty}b_n = 0$.
  \end{enumerate}
  Then $\sum b_n\vec{a}_n$ converges.
\end{thm}
\begin{proof}
  Since $\{\vec{A}_n\}$ is bounded we can find $M$ such that
  $\abs{\vec{A}_n}\leq M$ for all $n$. Given $\varepsilon>0$ there is
  an integer $N$ such that $b_N\leq\varepsilon/2M$. For
  $N\leq p\leq q$, we have
  \begin{align*}
    \Abs{\sum_{n=p}^qb_n\vec{a}_n}
    &= \Abs{\sum_{n=p}^q(b_n - b_{n+1})\vec{A}_n
      + b_q\vec{A}_q - b_p\vec{A}_{p-1}} \\
    &\leq M\Abs{\sum_{n=p}^{q-1}(b_n - b_{n+1}) + b_q + b_p} \\
    &= 2Mb_p\leq 2Mb_N\leq\varepsilon.
  \end{align*}
  Therefore $\sum b_n\vec{a}_n$ converges by the Cauchy criterion.
\end{proof}
\begin{thm}
  If $\sum\vec{a}_n$ converges absolutely, then $\sum\vec{a}_n$
  converges.
\end{thm}
\begin{proof}
  From the triangle inequality, we have
  \begin{equation*}
    \Abs{\sum_{k=n}^m\vec{a}_k}\leq\sum_{k=n}^m\abs{\vec{a}_k},
  \end{equation*}
  so the series $\sum\vec{a}_n$ converges by the Cauchy criterion.
\end{proof}
\begin{thm}
  If $\sum\vec{a}_n = \vec{A}$, and $\sum\vec{b}_n = \vec{B}$, then
  $\sum(\vec{a}_n+\vec{b}_n) = \vec{A} + \vec{B}$, and
  $\sum c\vec{a}_n = c\vec{A}$, for any fixed $c$.
\end{thm}
\begin{proof}
  For each $n\geq0$, set
  \begin{equation*}
    \vec{A}_n = \sum_{k=0}^n\vec{a}_k
    \quad\text{and}\quad
    \vec{B}_n = \sum_{k=0}^n\vec{b}_k.
  \end{equation*}
  Then
  \begin{equation*}
    \vec{A}_n + \vec{B}_n = \sum_{k=0}^n(\vec{a}_k + \vec{b}_k)
    \quad\text{and}\quad
    c\vec{A}_n = \sum_{k=0}^nc\vec{a}_n.
  \end{equation*}
  So
  \begin{equation*}
    \lim_{n\to\infty}(\vec{A}_n + \vec{B}_n)
    = \lim_{n\to\infty}\vec{A}_n
    + \lim_{n\to\infty}\vec{B}_n = \vec{A} + \vec{B}
  \end{equation*}
  and
  \begin{equation*}
    \lim_{n\to\infty}c\vec{A}_n = c\vec{A}. \qedhere
  \end{equation*}
\end{proof}
\begin{thm}
  If $\sum\vec{a}_n$ is a series of vectors which converges
  absolutely, then every rearrangement of $\sum\vec{a}_n$ converges,
  and they all converge to the same sum.
\end{thm}
\begin{proof}
  Again, the proof is mostly identical:

  Let $\sum\vec{a}_n'$ be a rearrangement, with
  $\vec{a}_n' = \vec{a}_{n_k}$ and with partial sums
  $\vec{s}_n'$. Given $\varepsilon > 0$, there exists an integer $N$
  such that
  \begin{equation*}
    \sum_{i=n}^m\abs{\vec{a}_i}\leq\varepsilon
    \quad\text{for all $m\geq n\geq N$}.
  \end{equation*}
  Choose $p$ such that the integers $1,2,\dots,N$ are all contained in
  the set $k_1,k_2,\dots,k_p$. Then if $n>p$, the vectors
  $\vec{a}_1,\dots,\vec{a}_N$ will cancel in the difference
  $\vec{s}_n - \vec{s}_n'$ so that
  $\abs{\vec{s}_n - \vec{s}_n'}\leq\varepsilon$. Hence
  $\{\vec{s}_n'\}$ converges to the same sum as $\{\vec{s}_n\}$.
\end{proof}
